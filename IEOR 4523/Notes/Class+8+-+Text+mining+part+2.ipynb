{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Text Summarization, Document Similarity, Topic Analysis</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FYI we can hide iPython warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Prepare restaurant corpus</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "restaurants = ['community', 'le_monde', 'shakeshack', 'fiveguys']\n",
    "restaurants_data = {}\n",
    "for restaurant in restaurants:\n",
    "    restaurants_data[restaurant] = PlaintextCorpusReader('Class 7 - Data/%s' % restaurant, '%s.*' % restaurant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Import nltk corpora</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load the inaugural address corpus</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_addresses = list()\n",
    "for file in inaugural.fileids():\n",
    "    all_addresses.append((file,inaugural.raw(file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Text summarization</h2>\n",
    "<li>Text summarization is useful because you can generate a short summary of a large piece of text automatically\n",
    "<li>Then, these summaries can serve as an input into a topic analyzer to figure out what the main topic of the text is\n",
    "<li>Text summarization typically selects \"important\" sentences and reports these sentences as a summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>A naive form of summarization is to identify the most frequent words in a piece of text and use the occurrence of these words in sentences to rate the importance of a sentence.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>First the imports</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from collections import OrderedDict\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Then prep the text. Get rid of end of line chars</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = restaurants_data['community'].raw()\n",
    "striptext = text.replace('\\n\\n', ' ')\n",
    "striptext = striptext.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Construct a list of words after getting rid of unimportant ones and numbers</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(striptext)\n",
    "lowercase_words = [word.lower() for word in words\n",
    "                  if word not in stopwords.words() and word.isalpha()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Construct word frequencies and choose the most common n (20)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequencies = FreqDist(lowercase_words)\n",
    "most_frequent_words = word_frequencies.most_common(20)\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(most_frequent_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Initializations</h4>\n",
    "<li>candidate_sentences is a dictionary with the original sentence as the key, and its lowercase version as the value\n",
    "<li>summary_sentences is a list containing the sentences that will be included in the summary\n",
    "<li>candidate_sentence_counts is a dictionary with the original sentence as the key, and the sum of the frequencies of each word in the sentence as the value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_sentences = []\n",
    "candidate_sentences = {}\n",
    "candidate_sentence_counts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(striptext)\n",
    "for sentence in sentences:\n",
    "    candidate_sentences[sentence] = sentence.lower()\n",
    "candidate_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for upper, lower in candidate_sentences.items():\n",
    "    count = 0\n",
    "    for freq_word, frequency_score in most_frequent_words:\n",
    "        if freq_word in lower:\n",
    "            count += frequency_score\n",
    "            candidate_sentence_counts[upper] = count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>sort the sentences by candidate_sentence_count</h4>\n",
    "<li>And pick the top ranked sentences</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_sentence_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_sentences = OrderedDict(sorted(\n",
    "                    candidate_sentence_counts.items(),\n",
    "                    key = lambda x: x[1],\n",
    "                    reverse = True)[:4])\n",
    "pp.pprint(sorted_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Packaging all this into a function</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_naive_summary(text):\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.tokenize import sent_tokenize\n",
    "    from nltk.probability import FreqDist\n",
    "    from nltk.corpus import stopwords\n",
    "    from collections import OrderedDict\n",
    "    summary_sentences = []\n",
    "    candidate_sentences = {}\n",
    "    candidate_sentence_counts = {}\n",
    "    striptext = text.replace('\\n\\n', ' ')\n",
    "    striptext = striptext.replace('\\n', ' ')\n",
    "    words = word_tokenize(striptext)\n",
    "    lowercase_words = [word.lower() for word in words\n",
    "                      if word not in stopwords.words() and word.isalpha()]\n",
    "    word_frequencies = FreqDist(lowercase_words)\n",
    "    most_frequent_words =word_frequencies.most_common(20)\n",
    "    sentences = sent_tokenize(striptext)\n",
    "    for sentence in sentences:\n",
    "        candidate_sentences[sentence] = sentence.lower()\n",
    "    for upper, lower in candidate_sentences.items():\n",
    "        count = 0\n",
    "        for freq_word, frequency_score in most_frequent_words:\n",
    "            if freq_word in lower:\n",
    "                count += frequency_score\n",
    "                candidate_sentence_counts[upper] = count   \n",
    "    sorted_sentences = OrderedDict(sorted(\n",
    "                        candidate_sentence_counts.items(),\n",
    "                        key = lambda x: x[1],\n",
    "                        reverse = True)[:4])\n",
    "    return sorted_sentences   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = '\\n'.join(build_naive_summary(restaurants_data['community'].raw()))\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = '\\n'.join(build_naive_summary(restaurants_data['le_monde'].raw()))\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>We can summarize George Washington's first inaugural speech<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_naive_summary(inaugural.raw('1789-Washington.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>gensim: another text summarizer</h2>\n",
    "<li>Gensim uses a network with sentences as nodes and 'lexical similarity' as weights on the arcs between nodes<p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk import sent_tokenize,word_tokenize \n",
    "from nltk.book import *\n",
    "import gensim.summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "restaurants = ['community', 'le_monde', 'shakeshack', 'fiveguys']\n",
    "restaurants_data = {}\n",
    "for restaurant in restaurants:\n",
    "    restaurants_data[restaurant] = PlaintextCorpusReader('Class 7 - Data/%s' % restaurant, '%s.*' % restaurant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(restaurants_data['community'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Initialize variables and clean data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = restaurants_data['community'].raw()\n",
    "summary_sentences = []\n",
    "candidate_sentences = {}\n",
    "candidate_sentence_counts = {}\n",
    "striptext = text.replace('\\n\\n', ' ')\n",
    "striptext = striptext.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = gensim.summarization.summarize(striptext, word_count=100) \n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = '\\n'.join(build_naive_summary(restaurants_data['community'].raw()))\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gensim.summarization.keywords(striptext,words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Comparing Trump's inaugural speech using the two methods</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = inaugural.raw('2017-Trump.txt')\n",
    "summary_sentences = []\n",
    "candidate_sentences = {}\n",
    "candidate_sentence_counts = {}\n",
    "striptext = text.replace('\\n\\n', ' ')\n",
    "striptext = striptext.replace('\\n', ' ')\n",
    "summary = gensim.summarization.summarize(striptext, word_count=100) \n",
    "print(summary)\n",
    "#print(gensim.summarization.keywords(striptext,words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = '\\n'.join(build_naive_summary(inaugural.raw('2017-Trump.txt')))\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Topic modeling</h1>\n",
    "<li>The goal of topic modeling is to identify the major concepts underlying a piece of text\n",
    "<li>Topic modeling uses \"Unsupervised Learning\". No a-priori knowledge is necessary\n",
    "<li>Though, without a-priori knowledge, your results are unlikely to be good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>LDA: Latent Dirichlet Allocation</h2>\n",
    "<li>A technique for topic modeling\n",
    "<li>Computes conditional probabilities for topic word sets\n",
    "<li>Identifies the most likely topics\n",
    "<li>Does this over multiple passes probabilistically picking topics in each pass\n",
    "<li>Good intuitive explanation: http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Basic assumptions:\n",
    "<ol>\n",
    "<li>Every document will be associated with a set of topics \n",
    "<li>The topics will be distributed across a probability distribution\n",
    "<li>Each topic will be represented in the document by a set of words\n",
    "<li>The words associated with the topic will be distributed across a probability distribution\n",
    "</ol>\n",
    "<li>Given these assumptions, LDA scans the document and tries to deduce the topic and word distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>tf-idf</h4>\n",
    "<li>tf-idf: term frequency - inverse document frequency\n",
    "<li>LDA increases the weight of words that occur frequently (tf)\n",
    "<li>But reduces the weight of words that occur across many documents in the document set (idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example</h3>\n",
    "<li>We'll look at the political news stories on slate.com\n",
    "<li>See what topics they cover\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Generate a list of story links\n",
    "<li>Get the stories and store in a document set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url=\"https://www.slate.com\"\n",
    "page = requests.get(url)\n",
    "bs_page = BeautifulSoup(page.content,'lxml')\n",
    "all_links = bs_page.find_all('a')\n",
    "categories = ['news_and_politics','news-and-politics']\n",
    "followable_links = list()\n",
    "for link in all_links:\n",
    "    href = link.get('href')\n",
    "    if href:\n",
    "        for cat in categories:\n",
    "            if cat in href:\n",
    "                followable_links.append(href)\n",
    "print(len(followable_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "followable_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_list = list()\n",
    "count=0\n",
    "for link in followable_links:\n",
    "    try:\n",
    "        page=BeautifulSoup(requests.get(link).content,'lxml')\n",
    "        text=page.find('body').find('section',class_='article__body').get_text().strip()\n",
    "        story_list.append(text)\n",
    "        count+=1\n",
    "    except:\n",
    "        continue\n",
    "print(count)       \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>imports for LDA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>prepare the text</h4>\n",
    "<li>Clean it (remove numbers, end of line characters, common words)\n",
    "<li>Sentence tokenize it\n",
    "<li>Convert each sentence into a list of words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(story_list)):\n",
    "    story = story_list[i]\n",
    "    sents = sent_tokenize(story)\n",
    "    for j in range(len(sents)):\n",
    "        sent = sents[j]\n",
    "        sent = sent.strip().replace('\\n','').replace('.', '')\n",
    "        sents[j] = sent\n",
    "    story_list[i] = '. '.join(sents)\n",
    "story_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Each document is converted into a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [[word for word in story.lower().split()\n",
    "        if word not in STOPWORDS and word.isalnum() and not word.lower() == 'slate']\n",
    "        for story in story_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Create a (word,frequency) dictionary for each word in the text</h4>\n",
    "<li>dictionary: corpora.Dictionary generates key = id , value = word (a unique number attached to each word). \n",
    "<li>corpus: A list of (word index, frequency) pairs for each text. doc2bow generates this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts) #(word_id,frequency) pairs\n",
    "corpus = [dictionary.doc2bow(text) for text in texts] #(word_id,freq) pairs by sentence\n",
    "dictionary[4]\n",
    "#dictionary.keys()\n",
    "#dictionary.token2id\n",
    "#corpus[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Do the LDA</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Parameters:</h4>\n",
    "<li>Number of topics: The number of topics you want generated. \n",
    "<li>Passes: The number of time the LDA model goes through the document. More passes, slower analysis\n",
    "<ol>\n",
    "<li>LDA first randomly assigns words and word weights to each topic\n",
    "<li>In each pass, it refines the weights\n",
    "<li>In short, you want the number of passes to be wherever the gain (improved weights) is minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set parameters\n",
    "num_topics = 5 #The number of topics that should be generated\n",
    "passes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel(corpus,\n",
    "              id2word=dictionary,\n",
    "              num_topics=num_topics,\n",
    "              passes=passes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>See results</h4>\n",
    "<li>We get a set of candidate topics in the form of words\n",
    "<li>It is up to us to make sense of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(lda.print_topics(num_words=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "lda.get_document_topics(corpus[0],minimum_probability=0.05)\n",
    "sorted(lda.get_document_topics(corpus[0],minimum_probability=0),key=itemgetter(1),reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Using the results</h2>\n",
    "<li>When a new document comes in\n",
    "<li>See which topic(s) it matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdoc = \"\"\"\n",
    "President Trump broke with his own intelligence agencies on Friday, appearing to accept Saudi Arabia’s explanation that the journalist Jamal Khashoggi was killed by accident during a fistfight, while the United States’ spy agencies are increasingly convinced that he was assassinated on high-level orders from the Saudi royal court.\n",
    "\n",
    "Mr. Trump, who has cultivated Crown Prince Mohammed bin Salman and made Saudi Arabia the linchpin of his Middle East strategy, has been deeply reluctant to point a finger at the prince, despite evidence linking him to Saudi operatives who entered the country’s consulate in Istanbul the same day that Mr. Khashoggi disappeared there.\n",
    "\n",
    "Asked during a visit to an Air Force base in Arizona whether he viewed the Saudi explanation as credible, Mr. Trump said, “I do.”\n",
    "\n",
    "[Jamal Khashoggi is dead. Here is everything we know so far.]\n",
    "\n",
    "The president said he still had questions for Prince Mohammed, and he called the killing of Mr. Khashoggi “unacceptable.” Mr. Trump also raised the possibility of sanctions against Saudi Arabia, but said that he hoped that Congress would not try to block billions of dollars in weapons sales to the kingdom, which he has held up as proof of the fruits of the alliance.\n",
    "\n",
    "Mr. Trump’s response sets up a clash with Congress, where Republicans and Democrats both tarred the Saudi explanation as lacking credibility. A senior lawmaker briefed on American intelligence assessments of the circumstances surrounding Mr. Khashoggi’s death, and the likely culprits, said it was not consistent with the Saudi account.\n",
    "\n",
    "The lawmaker, Representative Adam B. Schiff of California, the senior Democrat on the House Intelligence Committee, said, “The kingdom and all involved in this brutal murder must be held accountable, and if the Trump administration will not take the lead, Congress must.”\n",
    "\n",
    "Senator Lindsey Graham, Republican of South Carolina and a close ally of Mr. Trump’s, declared in a Twitter post, “To say that I am skeptical of the new Saudi narrative about Mr. Khashoggi is an understatement.” He added, “It’s hard to find this latest ‘explanation’ as credible.”\n",
    "\n",
    "The growing evidence that Mr. Khashoggi, a Virginia resident and a columnist for The Washington Post, was killed on orders from the Saudi royal family has put Mr. Trump in an increasingly untenable position.\n",
    "\n",
    "On Friday evening, the president praised the statement issued by the Saudi government, which confirmed Mr. Khashoggi’s death, as a “good first step” and a “big step.” Earlier, the prince and other senior Saudi officials had denied any role in Mr. Khashoggi’s disappearance.\n",
    "\n",
    "Editors’ Picks\n",
    "\n",
    "11 Takeaways From The Times’s Investigation Into Trump’s Wealth\n",
    "\n",
    "50 Years Later, It Feels Familiar: How America Fractured in 1968\n",
    "\n",
    "How to Buy a Gun in 15 Countries\n",
    "Secretary of State Mike Pompeo spoke with Prince Mohammed by phone on Friday evening and then briefed Mr. Trump and his national security adviser, John R. Bolton, according to a White House spokesman.\n",
    "\n",
    "“I think we’re getting close to solving a big problem,” Mr. Trump told reporters at the Luke Air Force Base, where he was shown an Apache helicopter, an F-35 fighter jet and an array of bombs.\n",
    "\n",
    "Image\n",
    "Representative Adam B. Schiff of California, the top Democrat on the House Intelligence Committee, in May on Capitol Hill. He was among the lawmakers who tarred the explanation by Saudi Arabia as lacking credibility.CreditTom Brenner/The New York Times\n",
    "For the president, Saudi Arabia has become a key ally but also a troublesome partner. Saudi support is critical to his efforts to isolate Iran. But he has watched as Prince Mohammed pursued a deadly war in Yemen, carried on a feud with his neighbor Qatar, jailed female dissidents and detained hundreds of wealthy Saudis.\n",
    "\n",
    "Mr. Trump’s son-in-law and senior adviser, Jared Kushner, cultivated a relationship with the prince, who is close to him in age and who Mr. Kushner hoped would be an advocate for his peace proposal between Israel and the Palestinians.\n",
    "\n",
    "In internal discussions, Mr. Kushner has urged the president and his aides not to abandon Prince Mohammed. But as Turkish officials leaked details of the grisly killing of Mr. Khashoggi and of the dismemberment of his body, the White House has become increasingly isolated in its defense of Saudi Arabia.\n",
    "\n",
    "A stream of prominent Wall Street and tech executives canceled plans to attend an investor conference convened by the prince next week in Riyadh, the Saudi capital. On Thursday, Steven Mnuchin, the Treasury secretary, pulled out of the conference, as well, though he will attend a separate meeting on counterterrorism strategy.\n",
    "\n",
    "In an interview on Thursday with The New York Times, Mr. Trump acknowledged that the furor over Mr. Khashoggi’s death had mushroomed into one of the biggest foreign policy crises of his presidency.\n",
    "\n",
    "“This one has caught the imagination of the world, unfortunately,” Mr. Trump said. “It’s not a positive. Not a positive.”\n",
    "\n",
    "The president also said on Thursday that it was still “a little bit early” in the process to draw definitive conclusions about who ordered the killing. But he expressed no doubt that the truth would come out soon.\n",
    "\n",
    "“We’re working with the intelligence from numerous countries,” he said, adding, “This is the best intelligence we could have.”\n",
    "\n",
    "On Wednesday, The Times reported that American intelligence officials were increasingly convinced that Prince Mohammed is culpable in Mr. Khashoggi’s death, and that they were preparing an appraisal for the White House.\n",
    "\n",
    "Saudi Arabia tried to project the idea of a housecleaning, announcing that Saud al-Qahtani, a close aide to the crown prince; Maj. Gen. Ahmed al-Assiri, the deputy director of Saudi intelligence; and other high-ranking intelligence officials had been dismissed.\n",
    "\n",
    "For Mr. Trump, who is on a three-day swing in the West before the midterm elections, the Khashoggi affair has become a distraction during a period in which he had hoped to campaign for Republican congressional candidates on a message of economic growth and the recent confirmation of Justice Brett M. Kavanaugh to the Supreme Court.\n",
    "\n",
    "Just after answering questions about the Saudi announcement, Mr. Trump flew to a “Make America Great Again” rally in Mesa, Ariz.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Clean and set up the text\n",
    "<li>Create corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = newdoc\n",
    "striptext = text.replace('\\n\\n', ' ')\n",
    "striptext = striptext.replace('\\n', ' ')\n",
    "new_text = [nltk.word_tokenize(striptext)]\n",
    "\n",
    "textdictionary = corpora.Dictionary(new_text) #(word_id,frequency) pairs\n",
    "corpus_new = [dictionary.doc2bow(text) for text in new_text] #(word_id,freq) pairs by sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Matching topics to documents</h2>\n",
    "<li>We now have a corpus with one document\n",
    "<li>Get the topics using the results of the lda we ran before \n",
    "<li>And see which topic(s) are the best matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "lda.get_document_topics(corpus_new[0],minimum_probability=0.05)\n",
    "sorted(lda.get_document_topics(corpus_new[0],minimum_probability=0),key=itemgetter(1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.print_topic(topicno=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Draw wordclouds</h4>\n",
    "<li>to better understand the topic we can draw wordclouds weighted by the weight of the terms in the topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_wordcloud(lda,topicnum,min_size=0,STOPWORDS=[]):\n",
    "    word_list=[]\n",
    "    prob_total = 0\n",
    "    for word,prob in lda.show_topic(topicnum,topn=50):\n",
    "        prob_total +=prob\n",
    "    for word,prob in lda.show_topic(topicnum,topn=50):\n",
    "        if word in STOPWORDS or  len(word) < min_size:\n",
    "            continue\n",
    "        freq = int(prob/prob_total*1000)\n",
    "        alist=[word]\n",
    "        word_list.extend(alist*freq)\n",
    "\n",
    "    from wordcloud import WordCloud, STOPWORDS\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    text = ' '.join(word_list)\n",
    "    wordcloud = WordCloud(stopwords=STOPWORDS,background_color='white',max_words=20, collocations=False).generate(text)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.imshow(wordcloud)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_wordcloud(lda,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Roughly,</h4>\n",
    "<li>lda looks for candidate topics assuming that there are many such candidates\n",
    "<li>looks for words related to the candidate topics\n",
    "<li>assign probablilites to those words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Understanding topics</h2>\n",
    "<li>pyLDAvis (package for visualizing the results of an LDA)\n",
    "<li>Shows topic distance between topics and top words in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(lda.print_topics(num_words=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "lda_display = pyLDAvis.gensim.prepare(lda, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Let's look at Presidential addresses to see what sorts of topics emerge from there</h3>\n",
    "<li>Each document will be analyzed for topic</li>\n",
    "<li>The corpus will consist of 58 documents, one per presidential address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inaugural.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [[word for word in inaugural.raw(file).lower().split()\n",
    "        if word not in STOPWORDS and word.isalnum() and not word.lower() == 'slate']\n",
    "        for file in inaugural.fileids()]\n",
    "dictionary = corpora.Dictionary(texts) #(word_id,frequency) pairs\n",
    "corpus = [dictionary.doc2bow(text) for text in texts] #(word_id,freq) pairs by sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create the model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel(corpus,\n",
    "              id2word=dictionary,\n",
    "              num_topics=10,\n",
    "              passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(lda.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "lda_display = pyLDAvis.gensim.prepare(lda, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>We can now compare presidential addresses by topic</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "sorted(lda.get_document_topics(corpus[0],minimum_probability=0,per_word_topics=False),key=itemgetter(1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_wordcloud(lda,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lda.show_topic(5,topn=5))\n",
    "print(lda.show_topic(4,topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1>Similarity</h1>\n",
    "<h2>Given a corpus of documents, when a new document arrives, find the document that is the most similar</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = [restaurants_data['community'],restaurants_data['le_monde'],restaurants_data['fiveguys'],restaurants_data['shakeshack']]\n",
    "all_text = restaurants_data['community'].raw() + restaurants_data['le_monde'].raw() + restaurants_data['fiveguys'].raw() + restaurants_data['shakeshack'].raw()\n",
    "\n",
    "documents = [doc.raw() for doc in doc_list]\n",
    "texts = [[word for word in document.lower().split()\n",
    "        if word not in STOPWORDS and word.isalnum()]\n",
    "        for document in documents]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.similarities.docsim import Similarity\n",
    "from gensim import corpora, models, similarities\n",
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2) # Latent Semantic Indexing\n",
    "doc = \"\"\"\n",
    "Many, many years ago, I used to frequent this place for their amazing french toast. \n",
    "It's been a while since then and I've been hesitant to review a place I haven't been to in 7-8 years... \n",
    "but I passed by French Roast and, feeling nostalgic, decided to go back.\n",
    "\n",
    "It was a great decision.\n",
    "\n",
    "Their Bloody Mary is fantastic and includes bacon (which was perfectly cooked!!), olives, \n",
    "cucumber, and celery. The Irish coffee is also excellent, even without the cream which is what I ordered.\n",
    "\n",
    "Great food, great drinks, a great ambiance that is casual yet familiar like a tiny little French cafe. \n",
    "I highly recommend coming here, and will be back whenever I'm in the area next.\n",
    "\n",
    "Juan, the bartender, is great!! One of the best in any brunch spot in the city, by far.\n",
    "\"\"\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]\n",
    "index = similarities.MatrixSimilarity(lsi[corpus])\n",
    "sims = index[vec_lsi]\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=\"\"\"\n",
    "Came to have lunch & also watch the World Cup match. I've been here many times before and not much has changed. \n",
    "\n",
    "You can get half off apps and bogo drinks when you sign up for their brew club. I tried their IPA \n",
    "(was not a fan).  We also ordered the backyarder and the hot mess burgers with a \n",
    "side of disco fries to share. Both were delicious and cooked perfectly. The fries were also really good - \n",
    "the gravy and the cheese mix worked perfectly. \n",
    "\n",
    "Service was not the best but it could have been because of how packed the bar was for the game. Still a \n",
    "solid option in the neighborhood. Should mention that the fried Oreos are out of this world!\n",
    "\"\"\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]\n",
    "index = similarities.MatrixSimilarity(lsi[corpus])\n",
    "sims = index[vec_lsi]\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
